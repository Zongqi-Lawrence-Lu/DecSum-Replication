# Sample Output and Pretrained Models

This folder contains example outputs, logs, and reference results from the DecSum Replication project.

Due to GitHub’s file size limits, large model files — including the _fine-tuned Longformer checkpoint_ (`.ckpt`) and _pretrained model weights_ — are **not included** in this repository.

##  Folder Structure

| File / Folder | Description |
|:---------------|:-------------|
| `dataset/` | Preprocessed Yelp train/valid/test splits (compressed JSON format) |
| `summary_result/` | Example summaries generated by the DecSum replication |
| `output/` | Example summary–score outputs |
| `pretrained_model/traing_log` | Training log for fine-tuning the longformer model | 
| `pretrained_model/model.ckpt` | *(external)* the Longformer `.ckpt` file | 
| `pretrained_model/pretrained/` | *(external)* model parameters and tokenizer files |

---

## Pretrained Model Download

The pretrained model and checkpoint are hosted externally on Google Drive:

**[Download model checkpoint and parameters here](https://drive.google.com/drive/folders/1rFf9nBx6-6__7fTdk1W4SBp-tJzXgoXX?usp=sharing)**

To use this model for inference, first decompress the pretrained folder

```bash
tar -xvzf pretrained.tar.gz
```

Change the environment variables in `summary/summary.py` to use them:

```python
score_model_name = "sample_output/pretrained"
```

## Note
These outputs are provided for reference and reproducibility; the results may differ depending on model seed and GPU version.

Make sure the model version and tokenizer match and both are `allenai/longformer-base-4096`.

To fine-tune the model from scratch, see the instruction in the main `README.md`.

